\section{Econometric Theory}
\subsection{Model and Estimation}
The econometric model used to forecast and its estimation method are closely related to Hansen \cite{hansen2009averaging} and Andrews \cite{andrews93}.\footnote{Andrews considers GMM as the primary estimation method.} The model we are interested in is a linear time series regression with a possible structural break in the conditional mean. The observations we have are time series $\{y_t,x_t\}$ for $t = 1,...,T$, where $y_t$\footnote{Since we are interested in forecasting, $y_t$ can be thought of as the variable to be predicted for the next period using currently available information $x_t$.} is the scalar dependent variable and $x_t$ is a $k\times 1$ vector of related predictors and possibly lagged values of $y_t$, $k$ is the total number of regressors or predictors included. Parameters are estimated by ordinary least squares. The forecasting model allowing for structural break is:
\begin{equation} \label{mod:1}
	y_t = x_t'\beta_1 I_{[t<m]} + x_t'\beta_2 I_{[t \geq m]} + e_t
\end{equation}
where $I_{[\bullet]}$ is an indicator function, $m$ is the time index of the break and $E(e_t|x_t) = 0$. The break date is restricted to the interval $[m_1,m_2]$ which is bounded away from the ends of the sample on both sides, $1 < m_{1} < m_{2} < T$. In practice, a popular choice is to use the middle $70\%$ portion of the sample. We assume that all information relevant for forecasting is included in the regressors $x_t$, and the source of model misspecification comes solely from the uncertainty about parameter stability. This is in contrast to many applied econometric models where model misspecification bias comes from the wrong choice of regressors but the parameters are assumed stable.

We can also use a stable linear model to forecast:
\begin{equation} \label{mod:2}
	y_t = x_t'\beta + e_t
\end{equation}
The traditional pre-test procedure starts with performing a test for structural breaks\footnote{This can be done in various ways. One is to treat various possible number of breaks as different models, then select one according to some information criterion, e.g., AIC, SIC or Mallow's. Another way is hypothesis testing, following the relevant testing procedures outlined in Andrews \cite{andrews93}, Bai and Perron \cite{bai_perron98} and Elliot and Muller \cite{elliott_muller_RES2006}.}, either by using Andrews' SupF or SupW test, or Bai and Perron's multiple-break test, and then decide to keep the stable or unstable model.

As an alternative to model selection, we can combine these two models by assigning weight $w$ to model~\ref{mod:1} and $1 - w$ to model~\ref{mod:2}, where $w \geq 0$. So the combined predictive model is
\begin{equation} \label{mod:3}
    y_{t} = w \left\{ x_t'\beta_1 I_{[t<m]} + x_t'\beta_2 I_{[t \geq m]} \right\} + (1 - w) \left\{ x_t'\beta \right\} + e_t
\end{equation}
With the forecasting model ready, next, we are going to present the cross-validation criterion in detail which is crucial in determining the optimal weight $w$ in equation~\ref{mod:3}.
\subsection{Cross-Validation Criterion}
There are several popular information criteria for model selection: for example, Akaike information criterion (\textbf{AIC}), corrected AIC (\textbf{AIC\textsuperscript{c}}), Schwarz Bayesian information criterion (\textbf{SIC}), Hannan-Quinn (\textbf{HQ}) and Mallows' C\textsubscript{p} (\textbf{C\textsubscript{p}}). Most criteria have two components in their formulas: the first part measures model fit while the second penalizes overfitting. The quantity measuring in-sample fit are the same for most criteria, but they differ in the degree of penalization. For instance, AIC penalizes each additional parameter by $2$ while SIC penalizes overfitting by the logarithm of sample size, so SIC tends to select a more parsimonious model than AIC if the sample size is large.

For the forecasting analysis, what we care about is the test error rate assessing the model predictive ability, not the training error rate produced in the model estimation stage, so selecting a information criterion which gives a good estimate of the expected test error rate is crucial. Cross-validation is such a criterion. Specifically, we focus on the use of leave-one-out cross-validation for this paper, though other CV variants, such as K--fold cross-validation, may be considered. Cross-validation is computationally simple for one-step ahead predictive model selection and is shown robust to conditional heteroscedasticity in the econometrics and statistics literature. For forecast combination, researchers have applied CV to the quadratic programming based model averaging analysis, but its setting does not include structural break.

The sample leave-one-out cross-validation criterion can be computed by the following procedure:
\begin{equation} \label{cv}
	CV_T(k) = \frac{1}{T}\sum_{t=1}^{T}\tilde{e}_{t}(k)^{2}
\end{equation}
where $\tilde{e}_{t}(k) = y_t - \tilde{\beta}_{-t}(k)'x_t(k)$ are the residuals from the regression with the $t^{\mathrm{th}}$ observation dropped and $\tilde{\beta}_{-t}(k) = (\sum_{i\not= t}x_i(k) x_i(k)')^{-1}(\sum_{i\not= t}x_i(k) y_i)$ is the associated vector of parameter estimates. Intuitively, this procedure is trying to estimate the expected test error rate based on the model training data. Though equation~\ref{cv} implies that we need to run regression $T$ times for given sample size $T$, luckily, for linear models, we can calculate sample CV value by running regression only once. Formally, the leave-one-out cross validation residuals can be computed from the full sample least squares residuals, $\tilde{e_{t}} = \frac{\hat{e_{t}}}{1 - h_{t}}$, where $h_{t} = x_{t}'(X_{t}'X_{t})^{-1}x_{t}$ is the leverage associated with observation $t$, $\hat{e_{t}}$ is the full sample least squares residual and $\tilde{e_{t}}$ is the cross-validation residual. So we can rewrite equation~\ref{cv} as
\begin{equation}
    CV_T(k) = \frac{1}{T}\sum_{t=1}^{T}\left( \frac{\hat{e_{t}}(k)}{1 - h_{t}} \right)^{2}
\end{equation}
In the next section we are going to show how model averaging weights are derived from the cross-validation criterion.
\subsection{Theoretical Results}
We assume that the true data generating process for $y_t$ takes the general parameter variation form and the change is of small magnitude so that the asymptotic distributions are asymptotically continuous. Also the change of the parameter value is proportional to the unconditional standard deviation of the error term. This makes sure that the impact of the local parameter instability is not dominated by that of the volatility. Under this assumption we can tell that the empirical model outlined in the previous section could be potentially misspecified: the single break model is only a special case of the general parameter variation model, with the absolute change of parameter values positive in one period while zero in others. In almost all relevant empirical work, researchers are interested in finding the best approximating model among all candidates available instead of looking for and estimating the true data generating process\footnote{There is research focusing on fitting data with complex models, such as nonlinear continuous break models. Though this approach may achieve good in-sample fit, its forecasting performance generally does not do well.}. Based on assumptions listed below, our method should give better MSFE under model averaging forecast for possibly misspecified models than other related methods.
\begin{assumption}\label{asump:1}
Assume the following holds:
\begin{enumerate}
	\item The true data generating process satisfies the linear model $y_t = x_t'\beta_t + e_t$, $t=1,...,T,\beta_t \in \mathbb{R}^k$, where $\beta_t = \beta + T^{-1/2}\eta(t/T)\delta\sigma_t$. $\eta(\bullet)$ is a $\mathbb{R}^k$ valued Riemann integrable function on $[0,1]$ and $\delta \in \mathbb{R}\backslash\{0\}$ is a scalar indexing the magnitude of parameter variation.
	\item $\{(x_t',e_t)\}$ is $\alpha$-mixing of size $-r/(r-2),r > 2$ or $\phi$-mixing of size $-r/(2r-2),r \geq 2$.
    \item $E(x_t e_t) = 0, \forall t$, and the process $\{x_t e_t\}$ is uniformly $L_r$-bounded, i.e., $||x_t e_t||_{r} < B$, where $B$ is a constant and $B < \infty$.
    \item $T^{-1/2}\sum_{t=1}^{[\pi T]} x_t e_t \Rightarrow W(\pi)$ where $W(\pi)$ is a $k \times 1$ Wiener process with symmetric, positive definite long-run covariance matrix $\Sigma \equiv \lim\limits_{T\to \infty}\mathrm{VAR}(T^{-1/2}\sum_{t=1}^{[\pi T]} x_t e_t)$, for $0 \leq \pi \leq 1$. ` $\Rightarrow$' denotes the weak convergence of the underlying probability measure as $T \to \infty$.
	\item $T^{-1}\sum_{t=1}^{[\pi T]}x_t x_t'$ converges uniformly to $\pi Q$ for all $\pi \in [0,1]$, $Q = E(x_t x_t')$ and all eigenvalues of $Q$ are uniformly bounded away from zero. $[\pi T]$ denotes the integer part of the product $\pi T$.
	\item $E(e_t^{2}|x_t) = \sigma_t^{2}$.
\end{enumerate}
\end{assumption}
Assumption 1.1 says that the true data generating process for $y_t$ takes a general parameter variation form and structural break occurs in all parameters. This assumption follows the theory proposed by Andrews and Hansen but is different from Bai and Perron who consider partial structural breaks. For Bai and Perron's \cite{bai_perron98} partial structural break model, there is no clear guidance on how to determine which set of regressors are subject to parameter instability. Without any prior information on the stability of parameters, it is natural to assume that all coefficients are subject to break. This full-break assumption is less restrictive and is used in many empirical applications, see Rapach and Wohar \cite{rapach_wohar_JFE2006} and Paye and Timmermann \cite{paye_timmermann_JEF2006}. This type of data generating process includes several commonly used cases, such as a single break, multiple breaks or continuous break process. Notice that our forecasting model outlined in the previous section only allows for one possible break in the parameters, so it could potentially be misspecified. We make this assumption and allow for the gap between the true DGP and the forecasting model primarily for two reasons. First, as argued by several researchers, for example, L\"{u}tkepohl \cite{lutkepohl_textbook}, the true data generating process for many macroeconomic and financial variables may be a complicated process possibly involving past values of infinite order. The main focus is not to search for the true DGP but to find the best approximating model, or the best local linear predictor based on available information. This assumption tries to capture the difficulty faced by many practitioners in forecasting. Second, a simple model is more likely to forecast better than many complex methods on average. Complicated methods may achieve good in-sample fit at the expense of compromising the forecasting model's adaptability to environment change\footnote{In an earlier version of this paper, through Monte Carlo simulation we provide an example to show that even the true DGP follows a continuous break process, the stable model forecasts best among all popular methods considered, such as Granger-Ramanathan combination.}.

Assumption 1.2 -- 1.5 ensure that we can apply all relevant mixing laws of large numbers, functional central limit theorem or Donsker's invariance principle when proving our results. See Davidson \cite{davidson_textbook} for more details on advanced asymptotic theory. Assumption 1.6 says that the error term could be conditionally homoscedastic or heteroscedastic, depending on the application of interest. This assumption contrasts our paper with Hansen's \cite{hansen2009averaging}, as Hansen only considers the conditionally homoscedastic error case.

Next, to obtain the main theoretical results, we need to derive the asymptotic distribution of the penalty term in the CV criterion since its first moment is crucial in determining the optimal weights in model averaging. We provide two theorems for the model averaging weights. Their differences depend on whether the assumption of conditional homoscedasticity holds. The proofs of all theoretical results are provided in the appendix.
\begin{proposition} \label{thm:1}
If assumption~\ref{asump:1} holds but $E(e_t^{2}|x_t) = \sigma^{2}$, the leave-one-out cross--validation criterion is asymptotically equivalent to Mallows' criterion, that is, $E(CV(T)) \stackrel{p}{\rightarrow} E(Cp(T))$.
\end{proposition}
\begin{corollary} \label{corollary:1}
The infeasible population optimal weight for the break model is $w = 1 - \frac{E(p_{\delta})}{\Sup_{\pi \in [\pi_{1}, \pi_{2}]}J_{0}(\pi)}$ for $\Sup_{\pi \in [\pi_{1}, \pi_{2}]}J_{0}(\pi) \geq E(p_{\delta}$ and $0$ otherwise. 
\end{corollary}
\begin{corollary} \label{corollary:2}
The feasible sample CV weight for the break model is:
\begin{equation}
\hat{w} = \frac{(T - 2k)(\sum_{t=1}^{T}\tilde{e}_{t}^{2} - \sum_{t=1}^{T}\hat{e}_{t}^{2}) - \bar{p}\sum_{t=1}^{T}\hat{e}_{t}^{2}}{(T - 2k)(\sum_{t=1}^{T}\tilde{e}_{t}^{2} - \sum_{t=1}^{T}\hat{e}_{t}^{2})}
\end{equation}
where $T$ is the sample size, $k$ is the number of regressors, $\hat{e}_t$s are the OLS residuals from the break model, $\tilde{e}_t$s are residuals from the stable model, $\bar{p}$ is the penalty coefficient whose value depends on the asymptotic distribution of the SupW test statistic.
\end{corollary}
This theorem shows that if we assume conditional homoscedasticity in the model, then the cross-validation information criterion is approximately identical to the Mallows' criterion\footnote{This is quite intuitive because the major advantage of CV over Mallows is that CV is robust to heteroscedasticity. If we assume away conditional heteroscedasticity, then these two criteria are basically equivalent.}, so all the model averaging results in Hansen \cite{hansen2009averaging}, i.e., optimal weights, hold here. See Hansen \cite{hansen2009averaging} for the table for $\bar{p}$ values.

It is widely known in the model selection literature that the CV criterion is superior to Mallows' and other information criteria because of its robustness to heteroscedasticity \cite{andrews_JE1991}. Our next lemma establishes the asymptotic distribution of the CV penalty term if we relax the assumption of conditional homoscedasticity.
\begin{lemma} \label{thm:2}
If Assumption~\ref{asump:1} holds under conditionally heteroscedastic errors, the penalty term in the cross-validation criterion converges in distribution to a weighted sum of independent $\chi^2$ distribution with degree of freedom one plus a term whose distribution is a function of Brownian bridge,
\begin{equation} \label{eq:4}
	e'P(\hat{k})e \stackrel{d}{\rightarrow} \sum_{j=1}^{k} \lambda_j \chi^2(1) + J_0(\xi_{\delta})
\end{equation}
where $\lambda_j$s are the eigenvalues of the matrix $L'Q^{-1}L$, $L$ comes from the decomposition of the positive definite matrix $\Sigma = LL'$, $\Sigma$ is the long-run variance of $\rn\jian X_t e_t$, $Q = E(x_t x_t')$ and $J_0(\xi_{\delta})$ is the asymptotic distribution of the Sup-Wald type statistic as in Andrews \cite{andrews93} under the true data generating process.
\end{lemma}
Now the asymptotic distribution of the penalty term involves a weighted sum of $\chi^2$ distributions and a Sup-Wald type distribution under the true data generating process. Comparing this result with the previous one, we can see that the distribution under conditional homoscedasticity is just a special case of the new one. That is, the weights for the $\chi^2$ random variables are identical and they take the value of one, which results in a $\chi^2$ distribution with degrees of freedom equal to the total number of regressors.

Notice that the new asymptotic distribution of the penalty term is non-standard, but its expectation is relatively easy to compute, which is the only moment we need to compute the optimal model averaging weights. The expectation of $\sum_{j=1}^{k} \lambda_j \chi^2(1)$ is simply $\sum_{j=1}^{k} \lambda_j$ which is the trace of the matrix $Q^{-1} \Sigma$, where $\Sigma$ is the long-run variance of $\rn\jian X_t e_t$ and $Q = E(x_t x_t')$. Empirically, $\Sigma$ can be estimated by HAC or HAR estimators and $Q$ can be consistently estimated by its sample analogue $\frac{1}{T}\sum_{t=1}^{T}x_t x_t'$. The following theorem provides the optimal weight for the break model under conditional heteroscedasticity.

\begin{theorem} \label{lem:2}
Suppose that $\hat{e}_t$s are the OLS residuals from the break model and $\tilde{e}_t$s are residuals from the stable model, then the optimal weight for the break model under conditional heteroscedasticity takes the form \footnote{$\mathrm{E(SupW(\pi_1,k))}$ is the expectation of the SupW distribution under the null of no break in Andrews' paper, evaluated at given values of $\pi$ and $k$. Note that the expectation of the SupW distribution under the true data generating process depends on unknown parameters, so Hansen suggests that in practice we can approximate its value by taking the averaging of two extreme cases: $\delta = 0$ and $\delta = \infty$. $\delta = 0$ implies that the distribution is identical to the SupW distribution under the null of no break. However, $\delta = \infty$ indicates that when the break size goes to infinity, essentially it is like we know exactly when the break happens, so its distribution becomes the $\chi^2$ type distribution whose first moment can be easily obtained without simulation.}:
\begin{equation} \label{eq:5}
	\hat{w} = 1 - \frac{\frac{1}{2}(\sum_{j=1}^{k}\lambda_j + \mathrm{E(SupW(\pi_1,k))})}{\sum_{t=1}^{T}\hat{e}_t^2 - \sum_{t=1}^{T}\tilde{e}_t^2}
\end{equation}
where the expectation of the SupW distribution depends on the number of regressors $k$ and the value of the trimming parameter, $\pi_1$\footnote{In practice, a popular choice of $\pi_1$ is $0.15$.}.
\end{theorem}
Note that the value of $\mathrm{E(SupW(\pi_1,k))}$ can be obtained from the $\bar{p}$ value\footnote{$\bar{p} = \frac{1}{2}(\mathrm{E(SupW(\pi_1,k))} + k)$} in Hansen \cite{hansen2009averaging}. The important part is the first component $\sum_{j=1}^{k}\lambda_j$ in the parentheses of equation~\ref{eq:5}. Intuitively, it captures the impact brought to the weight by allowing for conditional heteroscedasticity. Theorem~\ref{lem:2} implies that when there is conditional heteroscedasticity, cross-validation weights are optimal in the sense of minimizing the mean squared forecast error. 