\section{Introduction}
Forecast combination or model averaging has been a useful tool employed by econometricians and industry forecasters in studying many macroeconomic and financial time series, for example, GDP growth rate, monthly unemployment rate, inflation rate and stock market returns. Combination methods such as Granger--Ramanathan, Bates--Granger, Bayesian model averaging, least squares combination, discounted mean square forecast error weights, time--varying combination and survey forecasts combination have been developed for forecasting under various settings. There are several reasons explaining the popularity of forecast combination or model averaging in empirical research. First, it is highly possible that a single forecasting model is misspecified due to information constraints. For example, predictors that potentially could help boost forecasting performance are not included in the underlying model, so combining forecasts or averaging models may help the forecaster better manage the risk induced in the forecasting process and take advantage of all available information. Even in a stationary world, the true data generating process may be a highly complicated nonlinear function of lags of infinite order and other variables. Most linear forecasting models proposed by researchers are only viewed as local approximations for the best linear predictor, so it is hard to believe that one model strictly dominates all others at all points in time. Rather, the best forecasting model may change over time. Due to small sample size and imperfect information, it is difficult to track the best model based on past forecasting performance. Averaging models can be taken as a way to make the forecasts more robust against misspecification bias. If the bias is idiosyncratic in each individual model, then combining forecasts from all candidate models may help average out this bias. Second, a forecasting model's adaptability to parameter instability or structural breaks may not be constant across time. Drastic government policy changes or financial institution reform may bring about structural breaks in the time series variable of interest. An example worth mentioning here is the Great Moderation. Many researchers agree that there is a structural break in the volatility of the U.S. GDP growth rate around mid-1980s as the series becomes less volatile since then. Other developed countries, such as Canada and Germany, experienced the same phenomenon starting around the same period. Arguments explaining this phenomenon include technology progress, monetary policy change and financial system reform, etc. Depending on the magnitude and the frequency of the break process, forecasters may prefer a non-stationary model in which all or some of the parameters are changed around the detected break dates to a stable model where all parameters are assumed constant. Problems arise when the magnitude of the break is small or the evidence of parameter instability is not convincing. In this case, the pre-test model---the single forecasting model selected based on hypothesis testing or information criteria may not be the best choice to generate forecasts in the sense of further reducing mean squared forecast error (\textbf{MSFE}). The estimation or dating of structural break can be very imprecise. The quality of the break dates estimates depends not only on the break size measured by some criterion, but also on whether the impact of the break is dominated by the volatility of the process\footnote{We have conducted simulation related to this case. Even if there is a break in the conditional mean of the DGP, as long as the magnitude of the break is strictly dominated by the variance of the error term, it turns out that the stable version of the DGP forecasts better than the true DGP in the sense of smaller root mean squared forecast error.}. Additionally, even for a selected time series of interest, for example, aggregate stock market returns, we have several choices of data frequency for consideration (i.e., monthly, quarterly and yearly data). It is hard to conclude that the estimated structural break dates from all frequencies coincide\footnote{For example, the estimated break date based on monthly data falls exactly into the same year if estimated using yearly data. There are several empirical papers related to dating structural breaks based on different data frequencies and models. Although these papers show clear evidence of structural break, but the estimates of break dates are very noisy as different model provides different estimate of dates. Since a forecaster needs to use the upstream model estimation results as input to predict the future, a highly noisy estimate of structural break date may have a highly negative impact on the quality of forecasts.}. Facing this model selection uncertainty, forecast combination may offer diversification gains that make it attractive to average the break and stationary models, rather than relying on a pre-test model. See Timmermann \cite{timmermann2006forecast} for a comprehensive survey of forecast combination.

In an empirical study of American aggregate equity market returns, Rapach, Strauss and Guo \cite{rsz2010} argue that forecast combination is a powerful tool against structural breaks in forecasting excess stock returns. For given sample split choices, they show that forecasts generated by pooling all fifteen models are more accurate than those obtain from any single forecasting model. The quality of forecasts is measured by Campbell and Thompson's \cite{campbell_thompson_RFS2008} out-of-sample $R^{2}$ statistic. But this paper does not provide detailed econometric theory explaining why forecast combination, for example, methods such as equal weight and discounted mean squared forecast error weight used in their paper, may help deal with structural break. Moreover, structural breaks can take various forms, such as discrete or continuous breaks in regression coefficients or unconditional variance. Their paper does not address under which type of parameter instability is it suitable to combine forecasts or models.

Though with these potential benefits mentioned above, a puzzle associated with forecast combination is that in many empirical applications, equally weighted forecast schemes, i.e., each candidate model receives weight one divided by the total number of models,tend to perform better than various optimal combination weights proposed by researchers, notably the Granger--Ramanathan combination. A paper attempting to explain this puzzle is written by Elliott \cite{elliott11}. Elliott argues that if the variance of the unforecastable component of the variable is large, the gains from optimal forecast combination will be strictly dominated by the unpredictable component. Additionally, the noise introduced by estimating various optimal combination weights, especially when the number of weights is large, further reduces combination gains. Another drawback of forecast combination is that in many empirical applications, researchers or industry practitioners tend to ignore the econometric models associated with these forecasts. In return, this may result in omitting potentially important information related to combination weights.

With all these benefits and drawbacks mentioned above in mind, in this paper, we focus on the situation where forecasts are generated by two competing models and study if we can come up with model averaging weights possibly superior to others in terms of dealing with structural break and conditional heteroscedasticity. These two models share the same regressors, but one has structural breaks in the regression coefficients while the other is stable. This framework applies to situations in which: (i).researchers or forecasters cannot find convincing evidence supporting structural breaks; (ii).breaks are of small magnitude, or (iii).the model is not correctly specified. Our paper adapts Hansen's Mallows model averaging method \cite{hansen2009averaging} to the study of out-of-sample forecasting with breaks. Specifically, we propose model averaging weights derived from the cross--validation information criterion combining the break model and the stable model. Cross--validation (\textbf{CV}) criterion is an unbiased estimate of the mean squared forecast error, so intuitively, it justifies the use of CV weights to forecast out-of-sample. Under the assumption of conditional homoscedasticity, we show that the cross--validation model averaging weights are approximately identical to Hansen's Mallows' weights. A natural extension is to relax this homoscedastic error assumption as it may not be relevant to many empirical applications. Studies have shown that the cross--validation criterion performs better than various rival criteria in terms of model selection under conditional heteroscedasticity, especially in the order selection of ARMA model. Our major contribution is to derive the cross--validation model averaging weights under conditional heteroscedasticity and to show that CV weights are the correct weights minimizing the population mean squared forecast error in this situation. Monte Carlo evidence and empirical examples are provided to support our results.

The remainder of the paper is organized as follows: Section 2 provides related literature review. Section 3 first describes the econometric model and the forecasting problem, then shows theoretical results for the model averaging weights. Section 4 presents Monte Carlo evidence. Section 5 provides empirical applications. Section 6 concludes. 