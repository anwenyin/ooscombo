\section{Introduction}
Forecast combination or model averaging has been a useful tool employed by econometricians and industry forecasters in studying many macroeconomic and financial time series, for example, GDP growth rate, monthly unemployment rate, inflation rate and stock market returns. Combination methods such as Granger--Ramanathan, Bates--Granger, Bayesian model averaging, least squares combination, time--varying combination and survey forecasts combination have been developed for forecasting under various settings. There are several reasons explaining the popularity of forecast combination or model averaging in empirical research. First, it is highly possible that a single forecasting model is misspecified due to information constraints. For example, predictors that potentially help boost forecasting performance are not included in the underlying model, so combining forecasts or averaging models may help the forecaster better manage the risk induced in the forecasting process and take advantage of all available information. Even in a stationary world, the true data generating process may be a highly complicated nonlinear function of lags of infinite order and other variables. Most linear forecasting models proposed by researchers are only viewed as local approximations, so it is hard to believe that one model strictly dominates all others at all points in time. Rather, the best forecasting model may change over time. Due to small sample size and imperfect information, it is difficult to track the best model based on past forecasting performance. Averaging models can be taken as a way to make the forecasts more robust against misspecification bias. Second, a forecasting model's adaptability to parameter instability or structural breaks may not be constant across time. Drastic government policy changes or financial institution reform may bring about structural breaks in the time series variable of interest. Depending on the magnitude and the frequency of the break process, forecasters may prefer a non-stationary model in which all or some of the parameters are changed around the detected break dates to a stable model where all parameters are assumed constant. Problems arise when the magnitude of the break is small or the evidence of parameter instability is not convincing. In this case, the pre-test model---the single forecasting model selected based on hypothesis testing or information criteria may not be the best choice to generate forecasts in the sense of further reducing mean squared forecast error (\textbf{MSFE}). Facing this model selection uncertainty, forecast combination may offer diversification gains that make it attractive to average the break and stationary models, rather than relying on a pre-test model. See Timmermann \cite{timmermann2006forecast} for a comprehensive survey of forecast combination.

A puzzle associated with forecast combination is that in many empirical applications, equally weighted forecast schemes perform better than various optimal combination weights proposed by researchers, notably the Granger--Ramanathan combination. A paper attempting to explain this puzzle is Elliott \cite{elliott11}. Elliott argues that if the variance of the unforecastable component of the variable is large, the gains from optimal forecast combination will be strictly dominated by the unpredictable component. Additionally, the noise introduced by estimating combination weights, especially when the number of weights is large, further reduces combination gains.

In an empirical study of American equity market returns, Rapach, Strauss and Guo \cite{rsz2010} argue that forecast combination is a powerful tool against structural breaks in forecasting excess stock returns. Unfortunately, they do not provide rigorous econometric theory supporting their claim and the use of their combination method. Moreover, structural breaks can take various forms, such as discrete or continuous breaks in regression coefficients or unconditional variance, and they do not address under which type of parameter instability is it suitable to combine forecasts or models.

Another drawback of forecast combination is that in many empirical applications, researchers or industry practitioners tend to ignore the econometric models associated with these forecasts. In return, this may result in omitting potentially important information related to combination weights. In this paper, we focus on the situation where forecasts are generated by two competing models. These two models share the same regressors, but one has structural breaks in the regression coefficients while the other is stable. This framework applies to situations in which: (i).researchers or forecasters cannot find convincing evidence supporting structural breaks; (ii).breaks are of small magnitude, or (iii).the model is not correctly specified. Our paper adapts Hansen's Mallows model averaging method \cite{hansen2009averaging} to the study of out--of--sample forecasting with breaks. Specifically, we propose model averaging weights derived from cross--validation criterion combining the break model and the stable model. Cross--validation (\textbf{CV}) criterion is an unbiased estimate of the mean--squared forecast error (MSFE), so intuitively it justifies the use of CV weights to forecast out-of-sample. Under the assumption of conditional homoscedasticity, we show that the cross--validation model averaging weights are approximately identical to Hansen's Mallows' weights. A natural extension is to relax the assumption of conditional homoscedasticity since it may not be relevant to many empirical applications. Studies have shown that cross--validation criterion performs better than various rival criteria in terms of model selection under conditional heteroscedasticity, especially in the order selection of ARMA model. Our major contribution is deriving the cross--validation model averaging weights under conditional heteroscedasticity and evaluate their performance in simulation and in an empirical application. 